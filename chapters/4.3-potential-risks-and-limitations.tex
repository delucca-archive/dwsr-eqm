\subsection{Potential risks and limitations}
\label{subsec:potential-risks-and-limitations}

In this section, I will discuss the limitations of the proposed solution for both predicting memory consumption, as well as automatically partitioning the data.

\subsubsection{Sensibility towards too many control statements}

A possible limitation for this solution is that it may not work if the algorithm has too many control statements.
\EB{Daniel, penso que o problema não é a quantidade de sentenças condicionais, mas sim a influência que elas têm nos comandos de alocação de memória e na dependência que elas têm no valor dos dados de entrada, em vez do shape. Note que se tivermos um único If que controla a alocação (ou não) de memória, ele traz muito mais desafios do que diversos ifs que controlam a execução de comandos que não afetam o consumo de memória.}
Depending on the structure of the algorithm, the amount of control statements may change the memory usage.

This limitation can be ignored if the memory allocation of the algorithm happens before the control statements. 
On this scenario, even with control statements that change drastically the execution of the algorithm the memory usage will not change. \EB{Seria legal mostrar um pequeno exemplo de pseudocódigo (de preferência de cálculo de atributos sísmicos) que ilustra este cenário.}

Either way, all the seismic operators and machine learning models being used are tensorial algorithms, which means that they do not have too many control statements. \EB{They may not have lots of ifs, by they have loops, which are algo control flow statements.}
Therefore, \EBRP{this}{we do not expect this} possible limitation \EBRP{will not}{to} be a problem during the research.

\subsubsection{Unpredictable bottlenecks}

There are two possible memory bottlenecks in the proposed solution: \ac{CPU} and \ac{GPU} memory \EB{consumption?}.
Seismic operators are likely to be \ac{GPU}-memory bounded, but I need to conduct experiments to verify this.

If the algorithms can be both \ac{GPU} memory and \ac{CPU} memory bounded, then the proposed solution must be able to handle both scenarios.

\subsubsection{Language-agnosticity}

The proposed solution is currently focused on using Python since it is the language used for the seismic operators and Dask~\cite{dask} itself.

Although Python is a popular language in the scientific community, it may not be the language of choice for all researchers.
This solution may not be language-agnostic at the moment.
However, in the future, I can improve the solution to accept algorithms from any language.

In the case of the algorithm-specific model, I can improve the training structure to accept algorithms from any language.
This can be done by allowing decoupling both the feature extraction, as well as the execution of the algorithm, from the training process.

In the case of the generic algorithm model, it is possible improve the feature-extraction part to allow more languages as well.
Since the only difference between the two strategies is allowing to exract features from the source code, a specialized feature extractor per-language should be enough.

\subsubsection{DASK's memory management}

Since \ac{DASF}~\cite{dasf} uses Dask~\cite{dask} under the hood, I need to understand how Dask~\cite{dask} manages memory.
As far as my initial research went, Dask~\cite{dask} has an automatic chunking feature that deals with executing the proper data partitioning as long as the developer can define the maximum chunk size in bytes.

This feature seems promising, and it may solve most of the challenges related to automatic data partitioning.
But, I may need to conduct proper experiments to understand exactly how this feature works and what are its limitations.
Depending on the results of such experiments, I may need to adapt the proposed solution to work with Dask's~\cite{dask} memory management.
