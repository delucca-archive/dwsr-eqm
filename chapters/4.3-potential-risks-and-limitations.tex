\subsection{Potential risks and limitations}
\label{subsec:potential-risks-and-limitations}

In this section, I will discuss the limitations of the proposed solution for both predicting memory consumption, as well as automatically partitioning the data.

\subsubsection{Memory usage variance based on the input data}

A possible limitation for this solution is that it may not work if the algorithm structure contains control statements that drastically change the memory usage of the algorithm.
For example, if the algorithm's memory usage varies depending on the data itself, then the proposed solution may not work.

It is important to mention that this limitation only happens if the control statement affects the memory allocation directly.
Even if the algorithm has many control statements that change the execution flow drastically, this limitation can be ignored if the memory allocation of the algorithm happens before those. 

Either way, all the seismic operators and machine learning models being used are tensorial algorithms, which means that their execution flow would not vary based on the input data.
Therefore, I do not expect this possible limitation to be a problem during the research.

\subsubsection{Unpredictable bottlenecks}

There are two possible memory bottlenecks in the proposed solution: \ac{CPU} and \ac{GPU} memory consumption.
Seismic operators are likely to be \ac{GPU}-memory bounded, but I need to conduct experiments to verify this.

If the algorithms can be both \ac{GPU} memory and \ac{CPU} memory bounded, then the proposed solution must be able to handle both scenarios.

\subsubsection{Language-agnosticity}

The proposed solution is currently focused on using Python since it is the language used for the seismic operators and Dask~\cite{dask} itself.

Although Python is a popular language in the scientific community, it may not be the language of choice for all researchers.
This solution may not be language-agnostic at the moment.
However, in the future, I can improve the solution to accept algorithms from any language.

In the case of the algorithm-specific model, I can improve the training structure to accept algorithms from any language.
This can be done by allowing decoupling both the feature extraction, as well as the execution of the algorithm, from the training process.

In the case of the generic algorithm model, it is possible improve the feature-extraction part to allow more languages as well.
Since the only difference between the two strategies is allowing to exract features from the source code, a specialized feature extractor per-language should be enough.

\subsubsection{DASK's memory management}

Since \ac{DASF}~\cite{dasf} uses Dask~\cite{dask} under the hood, I need to understand how Dask~\cite{dask} manages memory.
As far as my initial research went, Dask~\cite{dask} has an automatic chunking feature that deals with executing the proper data partitioning as long as the developer can define the maximum chunk size in bytes.

This feature seems promising, and it may solve most of the challenges related to automatic data partitioning.
But, I may need to conduct proper experiments to understand exactly how this feature works and what are its limitations.
Depending on the results of such experiments, I may need to adapt the proposed solution to work with Dask's~\cite{dask} memory management.
