\subsection{Problems to be addressed}
\label{subsec:problems-to-be-addressed}

In this section, I will outline the potential problems that I may encounter during our research and how I plan to address them.
Each problem is going to be presented as a subsection, with a brief description of the problem and how I plan to address it.

\subsubsection{How to measure memory usage}

One of the primary challenges in our research is accurately measuring memory usage.
This is particularly true for \ac{GPU} memory, which may differ from \ac{CPU} memory.
I aim to explore different options to measure memory usage accurately.

I plan to start by investigating if there is an API to measure \ac{GPU} memory \EBADD{consumption}, and if not, I will explore common libraries that allow gathering memory consumption based on a specific process.
I understand that the optimal approach would be to use a specific API for this, since this would allow more flexibility for our tool, but I will explore alternative options if necessary.

\subsubsection{Historical data requirements}

Many of the current approaches require a significant amount of historical data to train the models.
This is not feasible for our research, as it would be time-consuming to generate such data for algorithm-specific models.
I aim to overcome this limitation by creating a proper discovery approach by merging reinforcement learning with Bayesian analysis.
\EB{Acho que faltou uma discussão sobre como você pensa em coletar os dados históricos. Talvez você pudesse ter uma seção ou parágrafo discutindo isso na proposta. Como exemplo, fiz uma figura no papel e enviarei para você via whats app.}

I plan to gather the minimal amount of data, even by executing the algorithm locally with a small amount of synthetic data, and then cover the exploration space for the input data for shapes and data with features the model have never seen before.
With this approach, I think the model will be able to learn while it is being used, and it will be able to generalize to new data.

\subsubsection{Python's garbage collection}

Python's garbage collector can pose a problem for us.
Python uses reference-counting as its garbage collection strategy, and it is lazy, so it usually waits for the memory to be needed to \EBRP{clean}{collect the garbage and free memory space}.
If our operators are \ac{CPU} memory bounded, I may need to figure out how to deal with Python's garbage collector to gather the real memory usage \EBADD{when collecting memory consumption information to train the ML models}.
However, I will only need to address this issue depending on the results of our experiments.

\subsubsection{Graph execution}

Another problem I may encounter is how to figure out the entire graph's memory requirements.
While our proposed solution can help us find the amount of memory required for a specific \EBC{algorithm}{Não estou certo, mas talvez o texto fique mais exato/claro se você definir o conceito de operador (ou operador DASF) na seção de background e usar este termo sempre que estiver se refereindo à rotina/operação que você quer analisar.}, integrating multiple algorithms into a graph poses a challenge.
I plan to address this issue by predicting not only the memory usage, but also the output shape of the algorithm and its features.
By having prior knowledge of the algorithms in the graph, I can compose a graph with the models using the output of the first model as the input data of the second one.
