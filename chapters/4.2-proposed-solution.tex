\subsection{Proposed solution}
\label{subsec:proposed-solution}

Most seismic operators are tensorial algorithms that execute calculations for each part of the input data.
Due to this fact, it is safe to assume that there might be a relationship between the memory usage of an algorithm and the shape of the input itself.
This research plans to create a reinforcement learning model that can optimize the chunking process by considering each task's memory footprint and adjusting the chunk size during the execution of the graph.

There are two different ways to implement the proposed solution:

\begin{enumerate}
  \item \textbf{Domain-specific model:} create a separate model for our domain, considering common input parameters, input shapes, and size as the primary features for the optimization;
  \item \textbf{Generic graph model:} create a single model capable of being graph-agnostic, considering the source code as a feature to describe the state during optimization.
\end{enumerate}

Although creating a generic model is more flexible, coding a domain-specific model will allow us to explore all possible limitations in a more controlled environment.
While coding the model, one of the first challenges is exploring which features may describe the current environment state for the optimization.
As a first hypothesis, the input data's shape and size may be the most relevant features since a large memory footprint is usually related to storing intermediate results.

Depending on the results of the initial experiments to create a domain-specific model, it is possible to expand the scope to a generic model.
In this scenario, all the tasks' source code within the graph may contain relevant information, such as how the code author deals with memory management.
However, it needs to be clarified how to extract features from the source code and use them to describe the current state during execution.

From a practical perspective, the reinforcement learning model will be responsible for the data partitioning process on \ac{DASF}~\cite{dasf}.
The goal is to create a plugin that can automatically decide the following action right after the execution of each task within the graph, allowing it to update to the optimal block size parameter during the execution of the graph.
